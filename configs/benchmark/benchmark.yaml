bench: inference # [inference|train|both|profile|all]
detail: False
no_retry: False
result_file: benchmark
num_warm_iter: 10
num_bench_iter: 40

model:
model_list:
batch_size: 256
input_size: [ 3,224,224 ]
use_train_size: False
num_classes: 1000
channels_last: True
amp: True
amp_dtype: float16

precision: float32
fuser: # te, old, nvfuser
torchscript: False
aot_autograd: False
fast_norm: False
grad_checkpointing: False

hydra:
  run:
    dir: benchmark_model/${model.model_name}_${now:%Y%m%d-%H%M%S}/

  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${now:%m-%d}_${now:%H-%M}_${hydra.job.name}_${model}.log
    root:
      handlers:
        - console
        - file
    disable_existing_loggers: false